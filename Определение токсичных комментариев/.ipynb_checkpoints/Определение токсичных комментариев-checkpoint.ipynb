{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание проекта:** Обучить модель классифицировать комментарии на позитивные и негативные. Значение метрики качества *F1* должно быть не меньше 0.75.\n",
    "\n",
    "Дан набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display_html\n",
    "\n",
    "# подготовка, обучение и проверка качества модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# работа с текстами\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/datasets/toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете 159571 объектов и два признака - один текстового типа, второй числового. Ознакомимся с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый признак 'text' содержит \"сырые\" тексты на английском языке. В текстах есть символы форматирования (например, обозначение переноса строки \\n), слова в разных регистрах. Признак 'toxic' целевой, похоже что бинарный. Изучим баланс классов в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts() / len(data['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в признаке всего два класса, значит будем решать задачу бнарной классификации. Токсичных комментариев в выборке мало - всего 10%, а значит имеет место дисбаланс классов. Есть несколько методов борьбы с дисбалансом. Например, некоторые модели могут самостоятельно перераспределять веса если это указать при настройке модели. Помимо этого можно провести апсемплинг/даунсемплинг выборки таким образом, чтобы снизить влияние дисбаланса на качество модели. Выбирать наиболее предпочтительный метод будем опираясь на ```confusion_matrix```, так как для нас важнее снизить количество ошибок при определении редкого класса.\n",
    "\n",
    "Разделим признаки на обучающий и целевой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь займемся подготовкой признаков. Для начала попробуем преобразование через лемматизацию и вычисление TF-IDF. Для лемматизации английских текстов воспользуемся библиотекой ```nltk```. Сначала очистим тексты от символов, использовав регулярные выражения, и приведем их к одному регистру, а затем лемматизируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleared_text(text):\n",
    "    return \" \".join(re.sub(r'[^a-zA-Z\\']', ' ', text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clear_text = cleared_text(text).lower()\n",
    "    lemm_text = \" \".join([lemmatizer.lemmatize(x, get_wordnet_pos(x)) for x in nltk.word_tokenize(clear_text)])\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним результат отдельным фаилом, так как лемматизация занимает немало времени и это может помешать при проверке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [lemmatize(x) for x in tqdm(features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data={'text': features}, index=data.index).to_csv(\"lemm_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_features = pd.read_csv(\"lemm_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 1 columns):\n",
      "text    159565 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "lemm_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно некоторые сообщения содержали в себе только символы, поэтому в данных появились пропуски. Удалим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_features.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отфильтруем таргеты по индексам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.iloc[lemm_features.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним текст до лемматизации и после."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my username hardcore metallica fan be revert they be n't vandalism just closure on some gas after i vote at new york doll fac and please do n't remove the template from the talk page since i 'm retire now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww he match this background colour i 'm seemingly stuck with thanks talk january utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i 'm really not try to edit war it 's just that this guy be constantly remove relevant information and talk to me through edits instead of my talk page he seem to care more about the format than the actual info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i ca n't make any real suggestion on improvement i wonder if the section statistic should be later on or a subsection of type of accident i think the reference may need tidy so that they be all in the exact same format ie date format etc i can do that later on if no one else do first if you have any preference for format style on reference or want to do it yourself please let me know there appear to be a backlog on article for review so i guess there may be a delay until a reviewer turn up it 's list in the relevant form eg wikipedia good article nomination transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember what page that 's on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_side_by_side(data[['text']].head(), lemm_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что тексты приведены к одному регистру, лишние символы исключены, слова приведены к базовой форме (например, множественное число к единственному, глаголы к начальной форме). Теперь разделим искомый датасет на две выборки - обучающую и тестовую, в пропорции 3:1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(lemm_features,\n",
    "                                                                            target,\n",
    "                                                                            test_size=0.25,\n",
    "                                                                            stratify=target,\n",
    "                                                                            random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом вычислим TF-IDF для полученных текстов. Не будем учитывать стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words, min_df=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = count_tf_idf.fit_transform(features_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(features_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей матрицы признаков:  (119673, 3046)\n",
      "Размер тестовой матрицы признаков:  (39892, 3046)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер обучающей матрицы признаков: \", tf_idf_train.shape)\n",
    "print(\"Размер тестовой матрицы признаков: \", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки подготовлены, выборки поделены. Приступим к обучению. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение\n",
    "\n",
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': ['l2', 'l1'], 'C': array([ 0.1       ,  0.46415888,  2.15443469, 10.        ]), 'solver': ['liblinear'], 'warm_start': [True, False], 'l1_ratio': [None, 0.3, 0.5, 0.7], 'class_weight': [None, 'balanced']}\n"
     ]
    }
   ],
   "source": [
    "penalty = [\"l2\", \"l1\"]\n",
    "C = np.logspace(-1., 1, num=4)\n",
    "solver = [\"liblinear\"]\n",
    "warm_start = [True, False]\n",
    "l1_ratio = [None, 0.3, 0.5, 0.7]\n",
    "class_weight = [None, \"balanced\"]\n",
    "\n",
    "log_grid = {'penalty': penalty,\n",
    "            'C': C,\n",
    "            'solver': solver,\n",
    "            'warm_start': warm_start,\n",
    "            'l1_ratio': l1_ratio,\n",
    "            'class_weight': class_weight}\n",
    "\n",
    "print(log_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров с кросс-валидацией закомментирован, чтобы сократить время загрузки проекта на ревью. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_test = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786, total=   1.0s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786, total=   1.0s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786, total=   1.0s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786, total=   0.9s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.46415888336127786, total=   0.9s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.8s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834, total=   1.9s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834, total=   2.2s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834, total=   2.0s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834, total=   2.0s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=None, class_weight=balanced, C=2.1544346900318834, total=   2.0s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786, total=   1.4s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786, total=   1.5s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786, total=   1.4s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786, total=   1.5s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.46415888336127786, total=   1.5s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834, total=   1.6s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834, total=   1.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834, total=   1.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834, total=   1.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=None, C=2.1544346900318834, total=   1.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.8s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.8s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.8s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.8s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.7, class_weight=None, C=0.1, total=   0.8s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1, total=   1.0s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1, total=   1.0s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1, total=   1.1s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1, total=   1.2s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l1, l1_ratio=0.3, class_weight=balanced, C=0.1, total=   1.0s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834, total=   1.3s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834, total=   1.5s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834, total=   1.5s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834, total=   1.2s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=2.1544346900318834, total=   1.4s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1 \n",
      "[CV]  warm_start=True, solver=liblinear, penalty=l2, l1_ratio=0.5, class_weight=None, C=0.1, total=   0.7s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0, total=   2.2s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0, total=   2.4s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0, total=   2.3s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0, total=   2.4s\n",
      "[CV] warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0 \n",
      "[CV]  warm_start=False, solver=liblinear, penalty=l1, l1_ratio=0.5, class_weight=balanced, C=10.0, total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "                   param_distributions={'C': array([ 0.1       ,  0.46415888,  2.15443469, 10.        ]),\n",
       "                                        'class_weight': [None, 'balanced'],\n",
       "                                        'l1_ratio': [None, 0.3, 0.5, 0.7],\n",
       "                                        'penalty': ['l2', 'l1'],\n",
       "                                        'solver': ['liblinear'],\n",
       "                                        'warm_start': [True, False]},\n",
       "                   random_state=357, refit='f1', scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log_random = RandomizedSearchCV(estimator=log_test, scoring=\"f1\",\n",
    "#     param_distributions=log_grid, verbose=2, refit=\"f1\",\n",
    "#     cv=5, random_state=357, n_jobs=-1)\n",
    "\n",
    "# log_random.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 лучшей модели при валидации:  0.757\n"
     ]
    }
   ],
   "source": [
    "log_random_best_score = 0.757\n",
    "\n",
    "print(\"F1 лучшей модели при валидации: \", log_random_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warm_start': False,\n",
       " 'solver': 'liblinear',\n",
       " 'penalty': 'l1',\n",
       " 'l1_ratio': 0.3,\n",
       " 'class_weight': None,\n",
       " 'C': 2.1544346900318834}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_best_params = {\n",
    "    'warm_start': False,\n",
    "    'solver': 'liblinear',\n",
    "    'penalty': 'l1',\n",
    "    'l1_ratio': 0.3,\n",
    "    'class_weight': None,\n",
    "    'C': 2.1544346900318834\n",
    "}\n",
    "\n",
    "log_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(**log_best_params, random_state=248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 44 ms, total: 2.14 s\n",
      "Wall time: 2.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.1544346900318834, l1_ratio=0.3, penalty='l1',\n",
       "                   random_state=248, solver='liblinear')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_model.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred = log_model.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на обучающей выборке:  0.9605759026681039\n",
      "F1 на тестовой выборке:  0.75120022592488\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 на обучающей выборке: \", log_model.score(tf_idf_train, target_train))\n",
    "print(\"F1 на тестовой выборке: \", f1_score(log_pred, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница в качестве обучающей и тестовой выборке около 0.2, что немало. Посмотрим как распределились ошибки по классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Target')\n",
    "    plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAG4CAYAAABGsp4tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3debxVdbn48c8DiJmoIJgDSPpTHNASFYHrUI6IZaHVNbXrlGmlljbdrCxT82ZzWWZqktrtpjaYaBjhlEOigCIqDqBpguSMOcPB5/fHXtiWOAOyzznw3Z93r/Vi7+/6rrW+C7VnP8/6rrUiM5EkSeXp0d0DkCRJncMgL0lSoQzykiQVyiAvSVKhDPKSJBXKIC9JUqEM8lKdiFgtIq6IiOci4jfLsZ+PRMSfGzm27hIRu0TE/d09DknLLrxPXiujiDgY+CywBfA8MB04PTNvWs79HgJ8CtgxM1uWe6AruIhIYEhmzu7usUhqPDN5rXQi4rPAD4H/AdYFBgM/BcY2YPdvBx5ohgDfERHRq7vHIOnNM8hrpRIRawGnAsdm5u8z88XMXJiZV2TmF6o+q0bEDyPisWr5YUSsWq3bNSLmRMTnIuKJiJgXEUdU604BvgZ8OCJeiIgjI+LrEfG/dcffKCJycfCLiMMj4qGIeD4i/hYRH6lrv6luux0jYkp1GWBKROxYt+76iDgtIm6u9vPniBjQyvkvHv9/141/v4h4T0Q8EBHPRMSX6/qPiIhbImJ+1fcnEdG7WndD1e3O6nw/XLf/L0bEP4BfLG6rttmkOsZ21fcNIuLJiNh1uf7BSuoUBnmtbP4DeAtwWRt9vgKMAoYB2wAjgJPq1q8HrAUMBI4EzoqIfpl5MrXqwCWZ2Sczz29rIBGxOnAmsE9mrgHsSO2ywZL91gb+WPXtD3wf+GNE9K/rdjBwBPA2oDfw+TYOvR61v4OB1H6UnAf8F7A9sAvw1YjYuOq7CPgMMIDa390ewDEAmfmuqs821fleUrf/talVNY6uP3BmPgh8EfjfiHgr8Avgwsy8vo3xSuomBnmtbPoDT7VTTv8IcGpmPpGZTwKnAIfUrV9YrV+YmROAF4DN3+R4XgO2jojVMnNeZt6zlD7vBWZl5i8zsyUzfw3cB7yvrs8vMvOBzHwZuJTaD5TWLKQ2/2AhcDG1AP6jzHy+Ov5Maj9uyMxpmTm5Ou7DwDnAuztwTidn5qvVeN4gM88DZgO3AutT+1ElaQVkkNfK5mlgQDvXijcAHqn7/kjV9vo+lviR8BLQZ1kHkpkvAh8GPgHMi4g/RsQWHRjP4jENrPv+j2UYz9OZuaj6vDgIP163/uXF20fEZhFxZUT8IyL+Sa1SsdRLAXWezMxX2ulzHrA18OPMfLWdvpK6iUFeK5tbgFeB/dro8xi1UvNig6u2N+NF4K1139erX5mZEzNzL2oZ7X3Ugl9741k8prlvckzL4mxq4xqSmWsCXwainW3avOUmIvpQm/h4PvD16nKEpBWQQV4rlcx8jtp16LOqCWdvjYhVImKfiPh21e3XwEkRsU41ge1rwP+2ts92TAfeFRGDq0l/X1q8IiLWjYix1bX5V6mV/V9byj4mAJtFxMER0SsiPgwMBa58k2NaFmsA/wReqKoMn1xi/ePA/1vGff4ImJqZH6M21+Bnyz1KSZ3CIK+VTmZ+j9o98icBTwKPAscBf6i6fAOYCswA7gJur9rezLEmAZdU+5rGGwNzj2ocjwHPULvWvWQQJTOfBvYFPkftcsN/A/tm5lNvZkzL6PPUJvU9T63KcMkS678OXFjNvj+gvZ1FxFhgDP86z88C2y2+q0DSisWH4UiSVCgzeUmSCmWQlySpUAZ5SZIKZZCXJKlQBnlJkgq1Qr1hKnqtltF7je4ehtRltt1ycHcPQepSjzzyME899VR7D2RqmJ5rvj2z5d+ezvym5MtPTszMMQ3ZWRdZsYJ87zVYdfN2b9WVinHzrT/p7iFIXWqnkcO79HjZ8nLD4sor089q85HQEfEW4AZgVWrx9beZeXJEXEDtORrPVV0Pz8zpERHUHi71HmqPsz48M2+v9nUY/3qx1jcy88KqfXvgAmA1ag/aOj7buBd+hQrykiQ1VkB02ZXpV4HdM/OFiFgFuCkirqrWfSEzf7tE/32AIdUyktpjqEdWj4o+GRhO7THT0yJifGY+W/U5itoLoiZQezjVVbTCa/KSpHIFENGYpR1Z80L1dZVqaeuJc2OBi6rtJgN9I2J9YG9gUmY+UwX2ScCYat2a1ZslE7iItt/jYZCXJKlRIqJnREwHnqAWqG+tVp0eETMi4gcRsWrVNpDaY7kXm1O1tdU+ZyntrTLIS5LKFj0as9Recz21bjl6yUNl5qLMHAYMAkZExNbUXmy1BbADsDbwxa46da/JS5LK1oFSewc9lZkdmjmYmfMj4jpgTGZ+t2p+NSJ+Qe3FUVB73fSGdZsNqtrmArsu0X591T5oKf1bZSYvSVIDVK+37lt9Xg3YC7ivupZONZt+P+DuapPxwKFRMwp4LjPnAROB0RHRLyL6AaOBidW6f0bEqGpfhwKXtzUmM3lJUsG6dHb9+tRe3dyTWhJ9aWZeGRHXRsQ6tcEwHfhE1X8CtdvnZlO7he4IgMx8JiJOA6ZU/U7NzGeqz8fwr1vorqKNmfVgkJckla5x5fo2ZeYMYNultO/eSv8Ejm1l3Thg3FLapwJbd3RMluslSSqUmbwkqVxBV5brVzgGeUlSwTr2IJtSNe/PG0mSCmcmL0kqm+V6SZIKZblekiSVxkxeklSwLn0YzgrHIC9JKtfiV802qeb9eSNJUuHM5CVJZbNcL0lSiZr7mnzznrkkSYUzk5ckla1H8068M8hLksrV5C+oad4zlySpcGbykqSyNfF98gZ5SVLBnF0vSZIKZCYvSSqb5XpJkgrVxOV6g7wkqVwRTZ3JN+/PG0mSCmcmL0kqm+V6SZIKZblekiSVxkxeklSw5n4YjkFeklQ2y/WSJKk0ZvKSpHI1+atmDfKSpII19zX55j1zSZIKZyYvSSpbE0+8M8hLkspmuV6SJJXGTF6SVDbL9ZIkFSicXS9JkgpkJi9JKpvlekmSyhRNHOQt10uSVCgzeUlSsYLmzuQN8pKkckW1NCnL9ZIkFcpMXpJUsGjqcr2ZvCSpaBHRkKUDx3lLRNwWEXdGxD0RcUrVvnFE3BoRsyPikojoXbWvWn2fXa3fqG5fX6ra74+Ivevax1RtsyPixPbGZJCXJKkxXgV2z8xtgGHAmIgYBXwL+EFmbgo8CxxZ9T8SeLZq/0HVj4gYChwIbAWMAX4aET0joidwFrAPMBQ4qOrbKoO8JKloXZXJZ80L1ddVqiWB3YHfVu0XAvtVn8dW36nW7xG1A40FLs7MVzPzb8BsYES1zM7MhzJzAXBx1bdVBnlJUtG6KshXx+oZEdOBJ4BJwIPA/MxsqbrMAQZWnwcCjwJU658D+te3L7FNa+2tMshLktQxAyJiat1y9JIdMnNRZg4DBlHLvLfo8lHWcXa9JKlcjb1P/qnMHN6Rjpk5PyKuA/4D6BsRvapsfRAwt+o2F9gQmBMRvYC1gKfr2her36a19qUyk5ckFStoTKm+g7Pr14mIvtXn1YC9gHuB64APVd0OAy6vPo+vvlOtvzYzs2o/sJp9vzEwBLgNmAIMqWbr96Y2OW98W2Myk5ckqTHWBy6sZsH3AC7NzCsjYiZwcUR8A7gDOL/qfz7wy4iYDTxDLWiTmfdExKXATKAFODYzFwFExHHARKAnMC4z72lrQAZ5SVLRuuphOJk5A9h2Ke0PUbs+v2T7K8B/trKv04HTl9I+AZjQ0TEZ5CVJReuqIL8i8pq8JEmFMpOXJBWtmTN5g7wkqVxN/qpZg7wkqWjNnMl7TV6SpEKZyUuSihVN/j55g7wkqWjNHOQt10uSVCgzeUlS2Zo3kTfIS5IKFpbrJUlSgczkJUlFa+ZM3iAvSSpaMwd5y/WSJBXKTF6SVCwfhiNJUsmaN8ZbrpckqVRm8pKkcjX5ffIGeUlS0Zo5yFuulySpUGbykqSiNXMmb5CXJJWteWO8Qb4Uq/buxdXnn0Dv3r3o1bMnl119B9/42QTOPeW/2GX7TXnuhVcAOPprv2TGA3Nf3277oYO5/sLPceiXfsFlV0/nXcOH8O3Pf/D19ZtvtC6HnvgLrrh+Bm/foD+/POMI1l5rde649+989KSLWNiyqMvPVWrPK6+8wp67vYsFr75Ky6IW9v/Ah/jqyaeQmXz9ayfx+9/9hp49e3LU0Z/k2E99GoAb/nI9X/jsCSxsWUj//gOYdO1fuvkspOVnkC/EqwtaGHP0mbz48gJ69erBteM+y59vngnAl3/4By67evq/bdOjR/CN48dy9eT7Xm+7YeosRh14BgD91nwrd48/masn3wvA6ceP5ce/uo7fTJzGmV85kMP3/w/O+81NXXB20rJZddVV+dOka+nTpw8LFy5k93fvzOi99+H+++5lzqOPcufd99GjRw+eeOIJAObPn8/xnzqGy6/8E4MHD369XWVo5nK9E+8K8uLLCwBYpVdPevXqSWa22f+YA9/NH665kyefeX6p6/ffc1v+fPNMXn5lIQDv3mEzfn/1HQD86opbed+u2zRw9FLjRAR9+vQBYOHChbQsXEhEcO45Z/Plk75Gjx61/+t729veBsAlv/4/xu73AQYPHvyGdq38IqJhy8rIIF+QHj2CyRefyN+vOYNrJ9/HlLsfAeDrx76P2y75Et/+3AfovUqteLPBOmvx/t234dzf3Njq/v5z7+249E/TAOjfd3Wee/5lFi16DYC5jz/LBm9bq5PPSHrzFi1axMjthzF4g7ex+557MWLkSP720IP89jeXsNPI4Yzddx9mz5oFwKxZDzD/2WcZvceu7Dhie371y4u6efRSY3RqkI+IMRFxf0TMjogTO/NYgtdeS0YdeAab7n0Sw7d+O0M3WZ+v/Xg82+x/Gjv/13fot9bqfO6IPQH4zhc+yEk/urzVbH+9AWuy1ZANmHTLzK48Balhevbsya3TpjP74TlMnXIb99x9N6+++iqrvuUt3HzrVI448ig+ftRHAWhpaeH226dx2fg/Mn7CRL75P6cx64EHuvkM1CjNnMl32jX5iOgJnAXsBcwBpkTE+Mw0anSy5154mb9MfYDROw7lh7+8BoAFC1u46PLJnHDoHgBsN3QwF51xBAD9+/Zh7523oqXlNa64fgYAH9xrO8ZfO4OWllrm/vT8F1lrjdXo2bMHixa9xsB1+/HYE891w9lJy6Zv3768e9fd+POf/8TAQYPYb78PADB2v/35+Mdq/w0MHDSI/v37s/rqq7P66quz887vYsaMOxmy2WbdOXQ1yMoaoBuhMzP5EcDszHwoMxcAFwNjO/F4TW1Avz6s1Wc1AN6y6irsMXIL7n/4cdYbsObrfd6/2zuZ+eBjAGy579fZ4r0ns8V7T+ayq+/ghG9e8nqABzhgzPZc+qepbzjGDVMf4AN7bgvAR943kivr+ksrkieffJL58+cD8PLLL3PN1ZPYfPMteN/79+Mv118HwI03/IVNh9SC+PveN5a/3nwTLS0tvPTSS0yZcitbbLFlt41fapTOnF0/EHi07vscYGQnHq+prTdgTc479RB69uhBjx7B7ybdzlU33s1V53yKAf3WIAJm3D+HT51+cbv7Grz+2gxarx83Tpv9hvav/OhyfnnGEZx8zL7cef+jXPCHWzrrdKTl8o958zjqo4exaNEiXsvX+OCHDuA9792XHXfamSMO/Qg//tEPWL1PH84+5+cAbLHlluy19xh22O6d9OjRg8OP+Bhbbb11N5+FGqZ5E3mivRnYb3rHER8CxmTmx6rvhwAjM/O4JfodDRwNwCp9tn/LVod1ynikFdGzU37S3UOQutROI4czbdrULgu7q647JAd+5EcN2dfffvDeaZk5vCE76yKdWa6fC2xY931Q1fYGmXluZg7PzOHRa7VOHI4kSc2lM8v1U4AhEbExteB+IHBwJx5PkqQ38lWznSMzWyLiOGAi0BMYl5n3dNbxJElaUgBNHOM797G2mTkBmNCZx5AkSUvns+slSQVbeR9k0wgGeUlS0Zo4xvvsekmSSmUmL0kqmuV6SZJKFM1drjfIS5KKFdRew92svCYvSVKhzOQlSUWzXC9JUqGaeeKd5XpJkhogIjaMiOsiYmZE3BMRx1ftX4+IuRExvVreU7fNlyJidkTcHxF717WPqdpmR8SJde0bR8StVfslEdG7rTEZ5CVJ5apm1zdi6YAW4HOZORQYBRwbEUOrdT/IzGHVMgGgWncgsBUwBvhpRPSMiJ7AWcA+wFDgoLr9fKva16bAs8CRbQ3IIC9JKlbtBTXRkKU9mTkvM2+vPj8P3AsMbGOTscDFmflqZv4NmA2MqJbZmflQZi4ALgbGRm0QuwO/rba/ENivrTEZ5CVJarCI2AjYFri1ajouImZExLiI6Fe1DQQerdtsTtXWWnt/YH5mtizR3iqDvCSpYI3J4qtMfkBETK1bjl7qESP6AL8DTsjMfwJnA5sAw4B5wPe66OSdXS9JKlsDJ9c/lZnD2z5WrEItwP8qM38PkJmP160/D7iy+joX2LBu80FVG620Pw30jYheVTZf33+pzOQlSWqA6pr5+cC9mfn9uvb167rtD9xdfR4PHBgRq0bExsAQ4DZgCjCkmknfm9rkvPGZmcB1wIeq7Q8DLm9rTGbykqSideF98jsBhwB3RcT0qu3L1GbHDwMSeBj4OEBm3hMRlwIzqc3MPzYzF1VjPg6YCPQExmXmPdX+vghcHBHfAO6g9qOiVQZ5SVK5uvAFNZl5U+2I/2ZCG9ucDpy+lPYJS9suMx+iNvu+QyzXS5JUKDN5SVKxFt8n36wM8pKkojVxjLdcL0lSqczkJUlFs1wvSVKhmjjGW66XJKlUZvKSpHKF5XpJkopUu4Wuu0fRfSzXS5JUKDN5SVLBwnK9JEmlauIYb7lekqRSmclLkopmuV6SpBJ14atmV0SW6yVJKpSZvCSpWL5qVpKkgjVzkLdcL0lSoczkJUlFa+JE3iAvSSqb5XpJklQcM3lJUrma/D55g7wkqVjhC2okSSpXE8d4r8lLklQqM3lJUtF6NHEqb5CXJBWtiWO85XpJkkplJi9JKlZEcz8MxyAvSSpaj+aN8ZbrJUkqlZm8JKloluslSSpUE8d4y/WSJJXKTF6SVKyg9vz6ZmWQlyQVzdn1kiSpOGbykqRyha+alSSpWE0c4y3XS5JUKjN5SVKxAl81K0lSsZo4xluulySpVGbykqSiNfPsejN5SVKxau+Tb8zS/rFiw4i4LiJmRsQ9EXF81b52REyKiFnVn/2q9oiIMyNidkTMiIjt6vZ1WNV/VkQcVte+fUTcVW1zZrTzC8YgL0lSY7QAn8vMocAo4NiIGAqcCFyTmUOAa6rvAPsAQ6rlaOBsqP0oAE4GRgIjgJMX/zCo+hxVt92YtgZkkJckFa1HREOW9mTmvMy8vfr8PHAvMBAYC1xYdbsQ2K/6PBa4KGsmA30jYn1gb2BSZj6Tmc8Ck4Ax1bo1M3NyZiZwUd2+lspr8pKkonXHFfmI2AjYFrgVWDcz51Wr/gGsW30eCDxat9mcqq2t9jlLaW+VQV6SpI4ZEBFT676fm5nnLtkpIvoAvwNOyMx/1l82z8yMiOz8odYY5CVJRWvg7PqnMnN4O8dahVqA/1Vm/r5qfjwi1s/MeVXJ/YmqfS6wYd3mg6q2ucCuS7RfX7UPWkr/VnlNXpJUrNoT7xqztHus2q+J84F7M/P7davGA4tnyB8GXF7Xfmg1y34U8FxV1p8IjI6IftWEu9HAxGrdPyNiVHWsQ+v2tVRm8pIkNcZOwCHAXRExvWr7MnAGcGlEHAk8AhxQrZsAvAeYDbwEHAGQmc9ExGnAlKrfqZn5TPX5GOACYDXgqmpplUFeklSuLnzVbGbeROvz/PZYSv8Ejm1lX+OAcUtpnwps3dExGeQlSUVr4gfeeU1ekqRStRvkI+IDHWmTJGlFFFXJfnmXlVFHMvmTltL2lUYPRJKkRuvK2fUrolavyUfE3tSeiTswIupvBVgTeK2zByZJkpZPWxPvngDuBl4B7qlrf55/PVxfkqQV2spaam+EVoN8Zt4B3BERv6KWuQ/OzNldNjJJkhqgeUN8x67J7wHcRe0tOETEsIi4rFNHJUlSA0R03VvoVkQdCfKnUnun7XyAzJwObNqZg5IkScuvIw/DWZiZ85e4ptFlb9CRJGl5rKRJeEN0JMjfGxEHAD0iYmPg08Dkzh2WJEmN0cwT7zpSrj8O2J7a5LvLgAXACZ05KEmStPzazeQz80Xgi9UiSdJKpYkT+faDfDWTfslr8M8BU4HzMnNBZwxMkqTlFay8M+MboSPl+keBFuCX1bKA2gNy3gmc13lDkyRJy6MjE+/+IzN3WPwlIv4A3JaZO0TEzM4bmiRJyyks17dnjYgYlJlzqu8bAGtUn1/tnGFJktQYzTy7viNB/r+BWyLiPmpPB9wMOC4iVgd+1cjBbLPlYP5y85mN3KW0Qnv+5YXdPQSpSy1KH7PSldoM8hHRA3icWmAfWjXPzMyXq8/f7cSxSZK03Doy+axUbQb5zHwtIs7JzGHAtC4akyRJDRE0d7m+Iz9wrouIsZ0+EkmS1FAduSZ/OHB8RLwKvEzth1Fm5tqdOTBJkhqhR/Mm8h0K8gM6fRSSJHUSg3wbMnNRRKwFbAK8pW7VXzttVJIkabl15LG2RwKfBQYCdwE7UHsL3a6dOjJJkpZThBPv2nMCMBx4ODN3ofZGuqc7dVSSJDVIj2jMsjLqSJB/ZfF98RHROzPvATbv3GFJkqTl1Wq5PiJ6ZWYLMC8i+gJXABMj4hlgTmvbSZK0Imnian2b1+RvA7bLzPdX378aEXsAawF/7PSRSZK0nAKa+lWzbQX5f/tbycxrOnEskiSpgdoK8utExGdbW5mZ3++E8UiS1FA+u37pegJ9WEpGL0nSyqKJq/VtBvl5mXlql41EkiQ11DJdk5ckaWUSEU68a8UeXTYKSZI6SRPH+NbnI2TmM105EEmS1FgdeQudJEkrrZX1kbSNYJCXJBWr2R+G08y3D0qSVDQzeUlS0Zo4kTfIS5IKthK/JrYRLNdLklQoM3lJUtGiiZ/tZpCXJBWrNru+u0fRfQzykqSiNXOQ95q8JEkNEBHjIuKJiLi7ru3rETE3IqZXy3vq1n0pImZHxP0RsXdd+5iqbXZEnFjXvnFE3Fq1XxIRvdsbk0FeklS0iGjI0gEXAGOW0v6DzBxWLROqMQ0FDgS2qrb5aUT0jIiewFnAPsBQ4KCqL8C3qn1tCjwLHNnegAzykqRiLb4m34ilPZl5A9DR976MBS7OzFcz82/AbGBEtczOzIcycwFwMTA2ar8ydgd+W21/IbBfewcxyEuS1LmOi4gZVTm/X9U2EHi0rs+cqq219v7A/MxsWaK9TQZ5SVK5ovbEu0YswICImFq3HN2BEZwNbAIMA+YB3+u8k/13zq6XJBWtgS+oeSozhy/LBpn5+OLPEXEecGX1dS6wYV3XQVUbrbQ/DfSNiF5VNl/fv1Vm8pIkdZKIWL/u6/7A4pn344EDI2LViNgYGALcBkwBhlQz6XtTm5w3PjMTuA74ULX9YcDl7R3fTF6SVKyufBhORPwa2JVaWX8OcDKwa0QMAxJ4GPg4QGbeExGXAjOBFuDYzFxU7ec4YCLQExiXmfdUh/gicHFEfAO4Azi/vTEZ5CVJReuqt9Bl5kFLaW41EGfm6cDpS2mfAExYSvtD1Gbfd5jlekmSCmUmL0kqWNDDF9RIklSeoOvK9Ssiy/WSJBXKTF6SVK4OPpK2VAZ5SVLRGvgwnJWO5XpJkgplJi9JKlazT7wzyEuSima5XpIkFcdMXpJUtCZO5A3ykqRyBc1dsm7mc5ckqWhm8pKkcgVEE9frDfKSpKI1b4i3XC9JUrHM5CVJxQqa+z55g7wkqWjNG+It10uSVCwzeUlS0Zq4Wm+QlySVLJr6FjrL9ZIkFcpMXpJUrGZ/rK1BXpJUNMv1kiSpOGbykqSiNW8eb5CXJJXMF9RIklSmZp9418znLklS0czkJUlFs1wvSVKhmjfEW66XJKlYZvKSpKI1cbXeIC9JKldtdn3zRnnL9ZIkFcpMXpJUNMv1kiQVKQjL9ZIkqTRm8pKkolmulySpQM6ulyRJRTKTlySVKyzXS5JUrGYO8pbrJUkqlJm8JKlo3icvSVKBAugRjVnaPVbEuIh4IiLurmtbOyImRcSs6s9+VXtExJkRMTsiZkTEdnXbHFb1nxURh9W1bx8Rd1XbnBnR/oUIg7wkSY1xATBmibYTgWsycwhwTfUdYB9gSLUcDZwNtR8FwMnASGAEcPLiHwZVn6PqtlvyWP/GIC9JKlo06H/tycwbgGeWaB4LXFh9vhDYr679oqyZDPSNiPWBvYFJmflMZj4LTALGVOvWzMzJmZnARXX7apXX5CVJRevm2fXrZua86vM/gHWrzwOBR+v6zana2mqfs5T2NhnkJUnqmAERMbXu+7mZeW5HN87MjIjshHG1ynJ9oY79+JFsMng9Rm3/ztfbvnHK19hxh2HsPHI79tt3b+Y99hgAzz77LB854APsuMMwdtt5FDPveX3OCPPnz+eQg/6T4dsMZYdhW3Hb5Fu6/Fykjpg751H2f+9e7LzDO9llxDac+9Mfv77u5z87ix2335pdRmzDKV898fX2e+6ewT577MIuI7bh3aO25ZVXXgHgzjtu592jtmXENlvy5S98hlp1VCurBpbrn8rM4XVLRwL841WpnerPJ6r2ucCGdf0GVW1ttQ9aSnubDPKFOviQw/jd5RPe0Pbpz3yev06Zzk233s6YffblW988DYDvffubvGObYfx1ynTOOf8Cvvj5z7y+zYmfP4E9R+/N1DtncvNtd7DZFlt26XlIHdWrVy9OOf3b3DRlBlddcxPjzjub+++byU03XM9VE67gur9O48bb7uSYT38WgJaWFo456nC+88OfcONtd3LZH69mlVVWAeC/P3Mc3zvzZ9w6fSYPPTibaydN7M5T03Loytn1rRgPLJ4hfxhweeIFWy4AAAyTSURBVF37odUs+1HAc1VZfyIwOiL6VRPuRgMTq3X/jIhR1az6Q+v21SqDfKF22vld9Ft77Te0rbnmmq9/fvGlF1l898X9983kXe/eDYDNNt+Cvz/yME88/jjPPfccN990I4cefiQAvXv3pm/fvl10BtKyWXe99XnnsG0B6LPGGmy2+RbMe+wxLjj/HD79mS+w6qqrArDOOm8D4PprJjF0q3ew9Tu2AWDt/v3p2bMnj/9jHs8//0+GjxhJRHDAQR9hwh/Hd89JaaUSEb8GbgE2j4g5EXEkcAawV0TMAvasvgNMAB4CZgPnAccAZOYzwGnAlGo5tWqj6vPzapsHgavaG5NBvsmcevJJDN307fzm4v/jK189BYCt37ENV1x+GQDTptzGo39/hLlz5/DIw39jwIB1OOboj7LzqO057pNH8eKLL3bn8KUO+fsjD3PXjDvZfvgIHpw9i8l/vYkxu+3E2H324I5ptUuqD86eVQvi+72XPXYZwY9/+F0A5j32GOsP/FdVdIOBg/hHdWlLK6NGFes7NLv+oMxcPzNXycxBmXl+Zj6dmXtk5pDM3HNxwK5m1R+bmZtk5jsyc2rdfsZl5qbV8ou69qmZuXW1zXHZgetInRbkl/ZQAHW/r53yDWbOfoT/PPBgzv3ZWQB85vNf5Lnn5rPzyO045+yf8M5ttqVnz560tLRw5/TbOfKoT3DT5Gms/tbV+cF3v9XNZyC17YUXXuCjh3yY0874LmusuSaLWlqY/+yzXHXtTZx82hkcdfjBZCYti1q4bfJfOfv8C7li4vVMuOJybrj+2u4evhqtekFNI5aVUWdm8hfQgRv11T0O+PDBjP/D74FaGf+n547jpltv55zzL+Tpp55ko43/HwMHDmLgwEEMHzESgLH7f5A7p9/encOW2rRw4UI++l8f5oMHHMS+798fgPU3GMR7378fEcF2w3cgogdPP/0UG2wwkFE77kz//gN461vfyp6jxzDjzjtYf4MNmDf3X3cqPTZ3DuttsEF3nZK0XDotyLfyUAB1owdnz3r984QrxzNks82B2gz6BQsWAHDhL37Ojjvvwpprrsm6663HwEEbMuuB+wH4y/XXsvkWQ7t+4FIHZCYnHHs0m22+BZ887oTX2/fZ9/3cdMP1ADw46wEWLlxA//4D2G2P0dw7825eeuklWlpa+OvNN7L55luy7nrrs8YaazL1tlvJTC799a/Y5z3v66azUiNEg5aVkffJF+qjhx7MTTf+haefeootNxnMl756Mn/+01XMnvUAPXr0YMPBg/nBmWcD8MB99/KJo44gIthiy6H85Gc/f30/3/7+j/jYEYewcMECNtpoY846d1x3nZLUplsn/5XfXPwrttxqa3bbaTgAX/naaRx8yOEcf8xRvGvkMFbp3Zsf/+x8IoK+/frxiWOPZ+9d/4OIYI/RY9hrzHsA+Nb3f8ynP3kkL7/8CnvstTd7jLYoubKqza5fWUP08ovOvP8zIjYCrszMrdvoczS15/ay4YaDt7/7gb912nikFc2rCxd19xCkLrXXu0cx/fZpXRZ1t3zHtjnususasq8dh/SblpnDG7KzLtLts+sz89zFDxbov8463T0cSVJhLNdLklSqlTVCN0Bn3kK3tIcCSJKkLtJpmXxmHtRZ+5YkqaM68iCbUlmulyQVrYkn1xvkJUlla+IY3/2z6yVJUucwk5ckla2JU3mDvCSpWLV73Js3yluulySpUGbykqRyrcSviW0Eg7wkqWhNHOMt10uSVCozeUlS2Zo4lTfIS5IKFs6ulyRJ5TGTlyQVzdn1kiQVKGjqS/KW6yVJKpWZvCSpbE2cyhvkJUlFc3a9JEkqjpm8JKlozq6XJKlQTRzjLddLklQqM3lJUrma/EZ5g7wkqWjOrpckScUxk5ckFStwdr0kScVq4hhvuV6SpFKZyUuSytbEqbxBXpJUNGfXS5Kk4pjJS5KK5ux6SZIK1cQx3nK9JEmlMpOXJJWtiVN5g7wkqVi199M0b5S3XC9JUqEM8pKkckVtdn0jlg4dLuLhiLgrIqZHxNSqbe2ImBQRs6o/+1XtERFnRsTsiJgREdvV7eewqv+siDjszZ6+QV6SVLRo0LIMdsvMYZk5vPp+InBNZg4Brqm+A+wDDKmWo4GzofajADgZGAmMAE5e/MNgWRnkJUll64Yov4SxwIXV5wuB/eraL8qayUDfiFgf2BuYlJnPZOazwCRgzJs5sEFekqTGSeDPETEtIo6u2tbNzHnV538A61afBwKP1m07p2prrX2ZObteklSwaOTs+gGLr7NXzs3Mc5fos3Nmzo2ItwGTIuK++pWZmRGRjRpQewzykqSiNfCxtk/VXWdfqsycW/35RERcRu2a+uMRsX5mzqvK8U9U3ecCG9ZtPqhqmwvsukT79W9mwJbrJUlqgIhYPSLWWPwZGA3cDYwHFs+QPwy4vPo8Hji0mmU/CniuKutPBEZHRL9qwt3oqm2ZmclLkoq1/HPmlsm6wGVRKx30Av4vM/8UEVOASyPiSOAR4ICq/wTgPcBs4CXgCIDMfCYiTgOmVP1Ozcxn3syADPKSpLJ1UZTPzIeAbZbS/jSwx1LaEzi2lX2NA8Yt75gs10uSVCgzeUlS0Zr52fUGeUlS0Ro4u36lY7lekqRCmclLkorWxIm8QV6SVLBleINciSzXS5JUKDN5SVLhmjeVN8hLkooVWK6XJEkFMpOXJBWtiRN5g7wkqWyW6yVJUnHM5CVJRfPZ9ZIklap5Y7zlekmSSmUmL0kqWhMn8gZ5SVK5wmfXS5KkEpnJS5KK5ux6SZJK1bwx3nK9JEmlMpOXJBWtiRN5g7wkqWzOrpckScUxk5ckFSycXS9JUokCy/WSJKlABnlJkgpluV6SVLRmLtcb5CVJRWvmiXeW6yVJKpSZvCSpXE3+qlmDvCSpWEFzP9bWcr0kSYUyk5ckla2JU3mDvCSpaM6ulyRJxTGTlyQVzdn1kiQVqoljvOV6SZJKZSYvSSpbE6fyBnlJUtGcXS9JkopjJi9JKlbQ3LPrIzO7ewyvi4gngUe6exxNaADwVHcPQupi/nvfPd6emet01cEi4k/U/lk3wlOZOaZB++oSK1SQV/eIiKmZOby7xyF1Jf+9VzPwmrwkSYUyyEuSVCiDvADO7e4BSN3Af+9VPK/JS5JUKDN5SZIKZZBvchExJiLuj4jZEXFid49H6mwRMS4inoiIu7t7LFJnM8g3sYjoCZwF7AMMBQ6KiKHdOyqp010ArFT3OktvlkG+uY0AZmfmQ5m5ALgYGNvNY5I6VWbeADzT3eOQuoJBvrkNBB6t+z6napMkFcAgL0lSoQzyzW0usGHd90FVmySpAAb55jYFGBIRG0dEb+BAYHw3j0mS1CAG+SaWmS3AccBE4F7g0sy8p3tHJXWuiPg1cAuweUTMiYgju3tMUmfxiXeSJBXKTF6SpEIZ5CVJKpRBXpKkQhnkJUkqlEFekqRCGeSldkTEooiYHhF3R8RvIuKty7GvXSPiyurz+9t6819E9I2IY97EMb4eEZ9/s2OUVA6DvNS+lzNzWGZuDSwAPlG/MmqW+b+lzByfmWe00aUvsMxBXpIWM8hLy+ZGYNOI2Cgi7o+Ii4C7gQ0jYnRE3BIRt1cZfx+AiBgTEfdFxO3ABxbvKCIOj4ifVJ/XjYjLIuLOatkROAPYpKoifKfq94WImBIRMyLilLp9fSUiHoiIm4DNu+xvQ9IKrVd3D0BaWUREL2Af4E9V0xDgsMycHBEDgJOAPTPzxYj4IvDZiPg2cB6wOzAbuKSV3Z8J/CUz94+InkAf4ERg68wcVh1/dHXMEUAA4yPiXcCL1B5JPIzaf9O3A9Mae/aSVkYGeal9q0XE9OrzjcD5wAbAI5k5uWofBQwFbo4IgN7UHp26BfC3zJwFEBH/Cxy9lGPsDhwKkJmLgOciot8SfUZXyx3V9z7Ugv4awGWZ+VJ1DN8/IAkwyEsd8fLibHqxKpC/WN8ETMrMg5bo94btllMA38zMc5Y4xgkNPIakgnhNXmqMycBOEbEpQESsHhGbAfcBG0XEJlW/g1rZ/hrgk9W2PSNiLeB5aln6YhOBj9Zd6x8YEW8DbgD2i4jVImIN4H0NPjdJKymDvNQAmfkkcDjw64iYQVWqz8xXqJXn/1hNvHuilV0cD+wWEXdRu54+NDOfplb+vzsivpOZfwb+D7il6vdbYI3MvJ3atf47gauovUJYknwLnSRJpTKTlySpUAZ5SZIKZZCXJKlQBnlJkgplkJckqVAGeUmSCmWQlySpUAZ5SZIK9f8BH7LI67oxAj0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 2)\n",
    "cnf_matrix_valid = confusion_matrix(target_test, log_pred)\n",
    "plot_confusion_matrix(cnf_matrix_valid, classes=['0', '1'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибки распределились удовлетворительно - большинство объектов редкого класса определились верно. Качество модели на тестовой выборке 0.75, что по условию задачи соответствует минимальному допустимому порогу.\n",
    "\n",
    "Попробуем решить проблему дисбаланса классов посредством проведения апсемплинга и даунсемплинга. Может быть это поможет улучшить качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Апсемплинг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 лучшей модели при валидации:  0.6696340257171117\n",
      "CPU times: user 13.3 s, sys: 456 ms, total: 13.8 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oversample_pipeline = make_pipeline(RandomOverSampler(random_state=123), \n",
    "                                    LogisticRegression(**log_best_params))\n",
    "\n",
    "log_oversample_score = cross_val_score(oversample_pipeline, tf_idf_train,\n",
    "                                       target_train, scoring='f1', cv=5)\n",
    "\n",
    "print(\"F1 лучшей модели при валидации: \", log_oversample_score.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Даунсемплинг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 лучшей модели при валидации:  0.6726238830219333\n",
      "CPU times: user 1.15 s, sys: 12 ms, total: 1.16 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "undersample_pipeline = make_pipeline(RandomUnderSampler(random_state=321), \n",
    "                                     LogisticRegression(**log_best_params))\n",
    "\n",
    "log_undersample_score = cross_val_score(undersample_pipeline, tf_idf_train,\n",
    "                                        target_train, scoring='f1', cv=5)\n",
    "\n",
    "print(\"F1 лучшей модели при валидации: \", log_undersample_score.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить качество модели за счет апсемплинга и даунсемплинга не удалось. Пока лучший результат у первой обученной модели логистической регрессии и он равен 0.75. Попробуем обучить еще одну модель. \n",
    "\n",
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'modified_huber', 'squared_hinge', 'perceptron'], 'penalty': ['l2', 'l1', 'elasticnet'], 'alpha': [0.0001, 0.005, 0.01], 'l1_ratio': [0.0, 0.15, 0.3], 'fit_intercept': [True, False], 'shuffle': [True, False], 'class_weight': ['balanced', None], 'warm_start': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "loss = ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive',\n",
    "        'hinge', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "penalty = ['l2', 'l1', 'elasticnet']\n",
    "alpha = [0.0001, 0.005, 0.01]\n",
    "l1_ratio = [0.0, 0.15, 0.3]\n",
    "fit_intercept = [True, False]\n",
    "shuffle = [True, False]\n",
    "class_weight = ['balanced', None]\n",
    "warm_start = [True, False]\n",
    "\n",
    "sgdc_grid = {'loss': loss,\n",
    "             'penalty': penalty,\n",
    "             'alpha': alpha,\n",
    "             'l1_ratio': l1_ratio,\n",
    "             'fit_intercept': fit_intercept,\n",
    "             'shuffle': shuffle,\n",
    "             'class_weight': class_weight,\n",
    "             'warm_start' : warm_start\n",
    "            }\n",
    "\n",
    "print(sgdc_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процесс подбора гиперпараметров закомментирован, чтобы сократить время загрузки проекта на ревью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgdc_test = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01 \n",
      "[CV]  warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01 \n",
      "[CV]  warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01 \n",
      "[CV]  warm_start=True, shuffle=True, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.15, fit_intercept=True, class_weight=None, alpha=0.01, total=   0.2s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=   0.3s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=   0.2s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=   0.2s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=   0.2s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=modified_huber, l1_ratio=0.0, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.3s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.3s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.3s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.3s\n",
      "[CV] warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=True, penalty=l1, loss=modified_huber, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.4s\n",
      "[CV] warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=elasticnet, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.1s\n",
      "[CV] warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.1s\n",
      "[CV] warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005 \n",
      "[CV]  warm_start=True, shuffle=False, penalty=l2, loss=squared_epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=None, alpha=0.005, total=   0.1s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01, total=   1.7s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01, total=   2.1s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01, total=   1.9s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01, total=   2.4s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.01, total=   2.0s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01, total=   0.3s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01, total=   0.3s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01, total=   0.3s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01, total=   0.4s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=squared_hinge, l1_ratio=0.3, fit_intercept=False, class_weight=None, alpha=0.01, total=   0.4s\n",
      "[CV] warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=  48.4s\n",
      "[CV] warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=  48.6s\n",
      "[CV] warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=  47.6s\n",
      "[CV] warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=  46.6s\n",
      "[CV] warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=elasticnet, loss=squared_hinge, l1_ratio=0.15, fit_intercept=False, class_weight=balanced, alpha=0.0001, total=  47.2s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   0.1s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   0.1s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=False, penalty=l2, loss=epsilon_insensitive, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   0.2s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   0.5s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   1.5s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   1.1s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   0.5s\n",
      "[CV] warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005 \n",
      "[CV]  warm_start=False, shuffle=True, penalty=l1, loss=hinge, l1_ratio=0.0, fit_intercept=True, class_weight=balanced, alpha=0.005, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=SGDClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.0001, 0.005, 0.01],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'l1_ratio': [0.0, 0.15, 0.3],\n",
       "                                        'loss': ['squared_loss', 'huber',\n",
       "                                                 'epsilon_insensitive',\n",
       "                                                 'squared_epsilon_insensitive',\n",
       "                                                 'hinge', 'modified_huber',\n",
       "                                                 'squared_hinge',\n",
       "                                                 'perceptron'],\n",
       "                                        'penalty': ['l2', 'l1', 'elasticnet'],\n",
       "                                        'shuffle': [True, False],\n",
       "                                        'warm_start': [True, False]},\n",
       "                   random_state=654, refit='f1', scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sgdc_random = RandomizedSearchCV(estimator=sgdc_test, scoring=\"f1\",\n",
    "#     param_distributions=sgdc_grid, verbose=2, refit=\"f1\",\n",
    "#     random_state=654, n_jobs=-1)\n",
    "\n",
    "# sgdc_random.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 лучшей модели при валидации:  0.655\n"
     ]
    }
   ],
   "source": [
    "sgdc_random_best_score = 0.655\n",
    "\n",
    "print(\"F1 лучшей модели при валидации: \", sgdc_random_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warm_start': False,\n",
       " 'shuffle': False,\n",
       " 'penalty': 'l2',\n",
       " 'loss': 'epsilon_insensitive',\n",
       " 'l1_ratio': 0.0,\n",
       " 'fit_intercept': True,\n",
       " 'class_weight': 'balanced',\n",
       " 'alpha': 0.005}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc_best_params = {\n",
    "    'warm_start': False,\n",
    "    'shuffle': False,\n",
    "    'penalty': 'l2',\n",
    "    'loss': 'epsilon_insensitive',\n",
    "    'l1_ratio': 0.0,\n",
    "    'fit_intercept': True,\n",
    "    'class_weight': 'balanced',\n",
    "    'alpha': 0.005\n",
    "}\n",
    "\n",
    "sgdc_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc = SGDClassifier(**sgdc_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 159 ms, sys: 0 ns, total: 159 ms\n",
      "Wall time: 170 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.005, class_weight='balanced', l1_ratio=0.0,\n",
       "              loss='epsilon_insensitive', shuffle=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sgdc.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc_pred = sgdc.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на обучающей выборке:  0.9432286313537723\n",
      "F1 на тестовой выборке:  0.655880149812734\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 на обучающей выборке: \", sgdc.score(tf_idf_train, target_train))\n",
    "print(\"F1 на тестовой выборке: \", f1_score(sgdc_pred, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим матрицу ошибок последней обученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 2)\n",
    "cnf_matrix_valid = confusion_matrix(target_test, sgdc_pred)\n",
    "plot_confusion_matrix(cnf_matrix_valid, classes=['0', '1'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Апсемплинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 лучшей модели при валидации:  0.6895119418483905\n",
      "CPU times: user 1.38 s, sys: 120 ms, total: 1.5 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oversample_pipeline = make_pipeline(RandomOverSampler(random_state=123), \n",
    "                                    SGDClassifier(**sgdc_best_params))\n",
    "\n",
    "sgdc_oversample_score = cross_val_score(oversample_pipeline, tf_idf_train,\n",
    "                                        target_train, scoring='f1', cv=5)\n",
    "\n",
    "print(\"F1 лучшей модели при валидации: \", sgdc_oversample_score.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Даунсемплинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 лучшей модели при валидации:  0.677872256278426\n",
      "CPU times: user 390 ms, sys: 20 ms, total: 410 ms\n",
      "Wall time: 420 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "undersample_pipeline = make_pipeline(RandomUnderSampler(random_state=321), \n",
    "                                     SGDClassifier(**sgdc_best_params))\n",
    "\n",
    "sgdc_undersample_score = cross_val_score(undersample_pipeline, tf_idf_train,\n",
    "                                        target_train, scoring='f1', cv=5)\n",
    "\n",
    "print(\"F1 лучшей модели при валидации: \", sgdc_undersample_score.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После проведения апсемплинга удалось немного улучшить качество модели до 0.68. Однако этого все равно мало, чтобы модель прошла по условию задачи.\n",
    "\n",
    "Соберем результаты кросс-валидации в одну таблицу, чтобы было удобнее выбрать наилучшую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Logistic Regression (oversampling)</th>\n",
       "      <th>Logistic Regression (undersampling)</th>\n",
       "      <th>SGD Classifier</th>\n",
       "      <th>SGD Classifier (oversampling)</th>\n",
       "      <th>SGD Classifier (undersampling)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>F1-value</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic Regression  Logistic Regression (oversampling)  \\\n",
       "F1-value                 0.76                                0.67   \n",
       "\n",
       "          Logistic Regression (undersampling)  SGD Classifier  \\\n",
       "F1-value                                 0.67            0.66   \n",
       "\n",
       "          SGD Classifier (oversampling)  SGD Classifier (undersampling)  \n",
       "F1-value                           0.69                            0.68  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(data={\n",
    "    'Logistic Regression': log_random_best_score,\n",
    "    'Logistic Regression (oversampling)': log_oversample_score.max(),\n",
    "    'Logistic Regression (undersampling)': log_undersample_score.max(),\n",
    "    'SGD Classifier': sgdc_random_best_score,\n",
    "    'SGD Classifier (oversampling)': sgdc_oversample_score.max(),\n",
    "    'SGD Classifier (undersampling)': sgdc_undersample_score.max()\n",
    "}, index=[\"F1-value\"]).round(2)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках задачи было необходимо обучить модель для поиска и отправки на модерацию потенциально токсичных комментариев. Для этого сначала нужно было подготовить признаки в соответствии с выбранным способом обработки. В качестве способа обработки был выбрана оценка важности через вычисление величины TF-IDF. Перед векторизацией, тексты были очищены от лишних символов, приведены к одному регистру, токенизированы, лемматизированы.\n",
    "\n",
    "После подготовки признаков было произведено обучение нескольких моделей классификации. При обучении был учтен дисбаланс классов — он был учтен как при настройке гиперпараметров, так и при помощи апсемплинга/даунсемплинга обучающей выборки. Модели сравнивались не только по величине F1-метрики, но также были сопоставлены их матрицы ошибок. В процессе сравнения было определено, что лучшей и наиболее гармоничной по F1-метрике и матрице ошибок получилась первая модель логистической регрессии (F1 = 0.76), а худшей — классификатор стохастического градиентного спуска (F1 = 0.66).\n",
    "\n",
    "При проверке модели логистической регрессии на тестовой выборке удалось достичь минимально допустимого значения F1-меры (F1 = 0.75)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
